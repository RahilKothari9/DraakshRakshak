from flask import Flask, request, jsonify
import torch
import torch.nn as nn
import torchvision.models as models
import torchvision.transforms as transforms
from PIL import Image
import io
import numpy as np
from sklearn.preprocessing import LabelEncoder
import requests
from twilio.twiml.messaging_response import MessagingResponse
import os
from dotenv import load_dotenv
import google.generativeai as genai
import re

# Load environment variables
load_dotenv()
TWILIO_ACCOUNT_SID = os.getenv('TWILIO_ACCOUNT_SID')
TWILIO_AUTH_TOKEN = os.getenv('TWILIO_AUTH_TOKEN')
GEMINI_API_KEY = os.getenv('GEMINI_API_KEY')

print("[INFO] Loaded environment variables")

# Gemini setup
genai.configure(api_key=GEMINI_API_KEY)
gemini_model = genai.GenerativeModel("gemini-2.0-flash")
print("[INFO] Gemini model initialized")

def get_crop_care_tips(disease_name):
    print(f"[INFO] Fetching crop care tips for: {disease_name}")
    prompt = f"""I detected a grape leaf disease called '{disease_name}'.
    Please give simple, clear care or treatment advice for a farmer in India. Keep it practical and actionable. Respond in 200 words"""
    response = gemini_model.generate_content(prompt)
    print("[INFO] Care tips fetched from Gemini")
    return response.text

def answer_general_question(user_question):
    print(f"[INFO] Answering general question: {user_question}")
    prompt = f"You are a helpful agriculture assistant for grape farmers in India. Answer the question clearly and practically: Respond in 200 words\n\n{user_question}"
    response = gemini_model.generate_content(prompt)
    print("[INFO] Answer generated by Gemini")
    return response.text

# Flask app
app = Flask(__name__)

# Model setup
class GrapeDiseaseModel(nn.Module):
    def __init__(self, num_classes=4):
        super(GrapeDiseaseModel, self).__init__()
        self.model = models.resnet18(pretrained=True)
        self.model.fc = nn.Linear(self.model.fc.in_features, num_classes)
    def forward(self, x):
        return self.model(x)

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"[INFO] Using device: {device}")

model = GrapeDiseaseModel().to(device)
model.load_state_dict(torch.load("grape_disease_model.pth", map_location=device, weights_only=True))
model.eval()
print("[INFO] Model loaded and ready")

transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
])

label_encoder = LabelEncoder()
label_encoder.classes_ = np.array(['Black Measles', 'Black Rot', 'Healthy', 'Isariopsis Leaf Spot'])

def predict_image(image):
    print("[INFO] Predicting image")
    image = image.convert("RGB")
    image = transform(image)
    image = image.unsqueeze(0).to(device)
    with torch.no_grad():
        output = model(image)
        _, predicted_class = torch.max(output, 1)
    pred = label_encoder.inverse_transform([predicted_class.cpu().item()])[0]
    print(f"[INFO] Prediction result: {pred}")
    return pred

@app.route("/predict", methods=["POST"])
def predict():
    if "file" not in request.files:
        return jsonify({"error": "No file provided"}), 400
    file = request.files["file"]
    if file.filename == "":
        return jsonify({"error": "Empty filename"}), 400
    try:
        image = Image.open(io.BytesIO(file.read()))
    except Exception as e:
        return jsonify({"error": str(e)}), 500
    prediction = predict_image(image)
    return jsonify({"prediction": prediction})

@app.route("/twilio/predict", methods=["POST"])
def twilio_predict():
    print("[INFO] Twilio webhook hit")
    resp = MessagingResponse()
    num_media = int(request.values.get('NumMedia', 0))
    body_text = request.values.get('Body', '').strip()
    print(f"[INFO] Received message â€” Text: {body_text}, Media Count: {num_media}")

    try:
        if num_media > 0:
            print("[INFO] Media found in request")
            media_url = request.values.get('MediaUrl0')
            print(f"[INFO] Media URL: {media_url}")
            headers = {'User-Agent': 'Mozilla/5.0'}
            image_response = requests.get(media_url, auth=(TWILIO_ACCOUNT_SID, TWILIO_AUTH_TOKEN), stream=True)
        elif body_text.startswith("http"):
            print("[INFO] URL received as text")
            headers = {'User-Agent': 'Mozilla/5.0'}
            image_response = requests.get(body_text, headers=headers, stream=True)
        elif body_text:
            print("[INFO] Text query received, passing to Gemini")
            answer = answer_general_question(body_text)
            resp.message(answer)
            return str(resp)
        else:
            print("[WARNING] No image or question detected")
            resp.message("Please send an image or a valid public image URL, or ask a crop-related question.")
            return str(resp)

        if image_response.status_code != 200:
            print(f"[ERROR] Image download failed: {image_response.status_code}")
            resp.message(f"Failed to download image: HTTP {image_response.status_code}")
            return str(resp)

        content_type = image_response.headers.get('Content-Type', '')
        if not content_type.startswith('image/'):
            print(f"[ERROR] Invalid content-type: {content_type}")
            resp.message("The file sent is not recognized as an image.")
            return str(resp)

        print("[INFO] Image downloaded successfully, predicting...")
        image = Image.open(io.BytesIO(image_response.content))
        prediction = predict_image(image)
        tips = get_crop_care_tips(prediction)
        cleaned_tips = re.sub(r"\*\*([^*]+)\*\*", r"\1", tips)  # Remove **bold**
        cleaned_tips = re.sub(r"\* ", "- ", cleaned_tips)       # Replace bullets
        cleaned_tips = re.sub(r"\n{2,}", "\n", cleaned_tips)     # Collapse double newlines
        cleaned_tips = cleaned_tips.strip()[:1200]               # Truncate safely

        final_message = f"Prediction: {prediction}\n\nCare Tips:\n{cleaned_tips}"
        print("[INFO] Final message sent to WhatsApp:", final_message)
        resp.message(final_message)


    except Exception as e:
        import traceback
        print("[EXCEPTION]", traceback.format_exc())
        resp.message("Something went wrong while processing the image or question. Please try again.")

    return str(resp)

if __name__ == "__main__":
    print("[INFO] Starting Flask app...")
    app.run(debug=True)
